---
title: ""
author: ""
date: ""
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{bedr}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
  %\SweaveUTF8
---

# An Introduction to bedr package

Introduction
------------


The  **bedr** package is a suite of tools for genomic interval processing.  The philosophy is to wrap existing best practice bioinformatic software in order to provide a unifying analysis environment within R.  **bedr** should be considered complimentary to native implementations of interval processing such genomicRanges.  

The advantages to this approach include:

* **Speed.**  Algorithms such as intersections have been heavily optimized in other software.
* **Size.** The operations happen outside of R and therefore are not constrained by memory to the same extent that R is.  Moreover, **bedr** allows for a hybrid analysis incorporating both R objects and huge on disk files
* **Consistency.** A vast number of standardized pipelines already use these tools, therefore simplifying implementation and integration.
* **Variety.**  Multiple tools *"engines"* are wrapped allowing for flexibility in choosing the ideal operation or cryptic functionality.
* **Visualization.** Need I say more.
* **Abstraction.** The existing utilities are only a subset of the native functionality found within each of the engines.  To directly access the full extent of options one can directly call the `bedr` including the required methods and parameters.  


Documentation
----------------------------

The current implementation focuses on three excellent tools.  For specifics on functionality please visit there online documentation, primary citation and [biostar](http://www.biostars.org/show/tag/bedtools/) posts.  To gain the functionality of these analytical engines you will need to have the programs installed and in your default PATH.  In future versions the source code for these dependencies may be distributed together.


1. bedtools [docs](http://bedtools.readthedocs.org/en/latest/) and [source](https://github.com/arq5x/bedtools2)
2. bedops [docs](https://bedops.readthedocs.org/en/latest/) and [source](https://github.com/alexpreynolds/bedops)
3. tabix [docs](http://www.htslib.org/doc/tabix.html) and [source](http://sourceforge.net/projects/samtools/files/tabix/)

General Region Utilities
----------------------------

* bedr.sort.region & is.sorted.region
* bedr.merge.region & is.merged.region
* in.region & order.region
* subtract.region
* flank.region & grow.region
* intersectRegion
* bedr.join.region & join.multiple.region
* get.RegionSize
* get.fastaRegion
* jaccard & reldist


For example:

First check if the regions are valid.  This involves checking for "chr" prefix, data types, end > start position and for compliance to bed formats zero based start position.  All checks can be turned off as required.  The "chr" check is useful due to various human reference formats (NCBI vs UCSC) having different standards.  This can result in unexpected results if comapring across specifications.  Similarly, bed format uses a zero based start postion, but vcf's use a one based position.  Therefore, a snp at position 100 would be chr1:100-100 in one based but chr1:99-100 in zero based format.  Another common mistake relates to overlaps between adjacent intervals, for example in zero based setups chr1:10-100 does not intersect with chr1:100-110. 

```{r, results = "hide", message = FALSE, eval = FALSE}
# load bedr library
library("bedr");

# region validation
index <- get.example.regions();
a <- index[[1]];
b <- index[[2]];
is.a.valid  <- is.valid.region(a);
is.b.valid  <- is.valid.region(b);
a <- a[is.a.valid];
b <- b[is.b.valid];

```

Generally, it's a good idea to confirm that you've sorted your inputs to avoid unexpected results and take advantage of optimized algorithms.  For example merging and clustering require adjacent intervals.  `is.sorted.region` is convenient for explicit evaluation although it's done internally for core operations.


```{r, results = "hide", message = FALSE, eval = FALSE}
### sort
is.sorted <- is.sorted.region(a);

a.sort <- bedr.sort.region(a);

b.sort <- bedr(engine = "bedtools", input = list(i = b), method = "sort", params = "");

```

Similarly, merging adjacent or overlapping regions is often required to avoid redundancy.  Doing an intersection/join with when you have redundant regions can cause unexpected results.

```{r, results = "hide", message = FALSE, eval = FALSE}
### merge or cluster
is.merged <- is.merged.region(a.sort);
is.merged <- is.merged.region(b.sort);

a.merge <- bedr.merge.region(a.sort);

# the explicit call uses the bedr function
b.merge <- bedr(engine = "bedtools", input = list(i = b.sort), method = "merge", params = "");

```

```{r, results = "hide", message = FALSE, eval = FALSE}
### subtract
a.sub1 <- bedr(input = list(a = a.merge, b = b.merge), method = "subtract", params="");
a.sub2 <- subtract.region(a.merge, b.merge);
```

```{r, results = "hide", message = FALSE, eval = FALSE}
### jaccard & relative distance
```

```{r, results = "hide", message = FALSE, eval = FALSE}
### in
is.region <- in.region(a.merge, b.merge);
# or alternatively
is.region <- a.merge %in.region% b.merge
```

```{r, results = "hide", message = FALSE, eval = FALSE}
### intersect / join
a.int3 <- join.region(a.merge, b.merge);
a.int1 <- bedr(input = list(a = a.sort, b = b.sort), method = "intersect", params = "-loj -sorted");

### multiple join
d <- get.random.regions(100, chr="chr1", sort = TRUE);
a.mult <- join.multiple.region(x = list(a.merge,b.merge,bedr.sort.region(d)));
```

```{r, results = "hide", message = FALSE, eval = FALSE}
### groupby 
# note the "g" column number is based on bed format i.e. first three columns chr, start, stop
# note the use of first, first, last on the region columns i.e. the union of the regions
# note currently missing values are note dealt with in bedtools.  also the 5th column is assumed to be "score" and gets a default "-1" not a "."
#cnv.gene <- bedr(input = list(i=cnv.gene), method = "groupby", params = paste("-g 16 -c ", paste(1:15, collapse = ","), " -o ", "first,first,last,", paste(rep("sum",12), collapse = ","), sep = ""));

```

Example 1: Compare Variant Callers
----------------------------
The example workflow below reads two VCF files from different variant callers, further limiting to structural variants only and finally identifying common calls.

```{r, results = "hide", message = FALSE, eval = FALSE}
options("warn" = -1);

VALID.SV.TYPES <- c('BND', 'CNV', 'DEL', 'DUP', 'INS', 'INV');
POSITION.COLUMNS <- c('CHROM', 'POS', 'END');

callerA.filename <- system.file("extdata/callerA.vcf.gz", package = "bedr");
callerB.filename <- system.file("extdata/callerB.vcf.gz", package = "bedr");

# read the VCF file
callerA <- read.vcf(callerA.filename, split.info = TRUE)$vcf;
callerB <- read.vcf(callerB.filename, split.info = TRUE)$vcf;

# focus on SVs
callerA <- callerA[which(callerA$SVTYPE %in% VALID.SV.TYPES), ];
callerB <- callerB[which(callerB$SVTYPE %in% VALID.SV.TYPES), ];

# convert to zero-based coordinates
callerA$POS <- callerA$POS - 1;
callerB$POS <- callerB$POS - 1;

# find all overlapping pairs, retrieve size of overlap (bp)
overlapping.pairs <- join.region(
    callerA[, POSITION.COLUMNS],
    callerB[, POSITION.COLUMNS],
    report.n.overlap = TRUE,
    check.chr = FALSE
    );
colnames(overlapping.pairs) <- c(
    'a.CHROM', 'a.POS', 'a.END',
    'nOverlap',
    'b.CHROM', 'b.POS', 'b.END'
    );
overlapping.pairs$b.POS <- as.numeric(overlapping.pairs$b.POS);
overlapping.pairs$b.END <- as.numeric(overlapping.pairs$b.END);

# compute a distance between overlapping pairs
min.breakpoint.distances <- cbind(
    overlapping.pairs$a.POS - overlapping.pairs$b.POS,
    overlapping.pairs$a.END - overlapping.pairs$b.END
    );

min.breakpoint.distances <- apply(
    abs(min.breakpoint.distances),
    1,
    min
    );
a.length <- overlapping.pairs$a.END - overlapping.pairs$a.POS;
b.length <- overlapping.pairs$b.END - overlapping.pairs$b.POS;

overlapping.pairs$distance  <- (min.breakpoint.distances + abs(a.length - b.length)) / 2;

```


Example 2: Exome Target Processing
----------------------------

Download target BED, RefGene

Validate the gene names

check & Sort & Merge

Add some slop

Adding gene names via join

Candidate gene list extract with in.region

identify regions with overlapping features ":"

Filter for non overlapping features and try again

Plot distribution of capture sizes

Plot venn of capture bed vs gene

```
### example 1
###  workflow adding gene names to exome sequencing target file
# download refseq genes from ucsc or query biomart for ensemble gene names.  format them in basic bed format.
# sort, merge target
# sort, merge -nms target.  Overlapping genes/features get merged.  this may not be ideal if there are some really big features.
# intersect -loj target, genes.
# alternatively, do not merge the target and apply the merge after the intersect.  this will provide precision a the level of the exon.
```

Example 2: Copy Number Recurrence
----------------------------

check 

Merge multiple samples

Filter problematic regions (telomeres, centromeres, encode blacklist)

merge to gene and then merge different platforms

Add some flank and calculate the similarity via jaccard

plot a heatmap with jaccard as the intersample distance metric

calculate reldist kw.test. multiple line plot for outliers.

summarize genes with highest proportion of CN gain/loss

calculate the pga and do a barplot.


Example 3. ClinVar Summarizing
----------------------------

tabix to get some bed data i.e. acmg genes

read.vcf to load some clinical data annotation

read.vcf to load some variants, 1kg??

summarize counts, type, consequence, ti-tv

stacked barplot


Example 4. Cosmic Munging
----------------------------

read.vcf

getfasta triplet nucleotide around variant

20-20 rule to id some TS and Onc's



